{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "Using word embeddings to (hopefully) improve prediction accuracy of our property listing classification data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleaning import process_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_json('property_descriptions.json')\n",
    "df['description'] = df['description'].apply(process_text)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['description'], df['advertiser'], test_size=0.3)\n",
    "sentences = []\n",
    "for descriptions in x_train:\n",
    "    sentences.append(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model.\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(sentences, workers=4, size=300, \n",
    "                          min_count = 40, window = 10, sample = 1e-3)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging vectors\n",
    "An option for utilising word2Vec is by averaging the word vectors within each sample of text. Pretty basic but worth checking out how well this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.75      0.83      0.79      2625\n",
      "   flatmate       0.70      0.73      0.71      2673\n",
      "   landlord       0.66      0.58      0.61      3043\n",
      "\n",
      "avg / total       0.70      0.70      0.70      8341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def average_text(text):\n",
    "    \"\"\"Use trained word2vec model to average property descriptions\"\"\"\n",
    "    text = text.values\n",
    "    text_matrix = np.zeros((text.shape[0], 300))\n",
    "    for i in range(text.shape[0]):\n",
    "        text_sum = 0\n",
    "        count = 0\n",
    "        words = text[i]\n",
    "        for word in words:\n",
    "            try:\n",
    "                text_sum += model.wv.get_vector(word)\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if count != 0:\n",
    "            text_matrix[i,:] = text_sum / count\n",
    "        else:\n",
    "            text_matrix[i,:] = np.zeros(300)\n",
    "    return text_matrix\n",
    "            \n",
    "x_train = average_text(x_train)\n",
    "x_test = average_text(x_test)\n",
    "\n",
    "# Train SVC with average vectors.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cal_lamont/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from cleaning import process_text\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags advertiser')\n",
    "\n",
    "# df = pd.read_json('property_descriptions.json')\n",
    "# df['description'] = df['description'].apply(process_text)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df['description'], df['advertiser'], test_size=0.3)\n",
    "sentences = []\n",
    "count = 0\n",
    "for listing in df.index:\n",
    "    sentences.append(SentimentDocument(df.loc[listing,'description'], [count], df.loc[listing,'advertiser']))\n",
    "    count += 1\n",
    "        \n",
    "model = doc2vec.Doc2Vec(size=100, window=4, min_count=5, workers=4)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing model or train new model\n",
    "# model = Doc2Vec.load('./imdb.d2v')\n",
    "\n",
    "from numpy.random import shuffle\n",
    "for epoch in range(10):\n",
    "    shuffle(list(all_sent))\n",
    "    model.train(sentences, total_examples=len(sentences), epochs=1)\n",
    "model.save('./listing_model.d2v')\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on 3/4 of the data\n",
    "import numpy as np\n",
    "idxs = np.random.permutation(range(len(sentences)))\n",
    "train_idxs = list(idxs[len(sentences)//4:])\n",
    "test_idxs = list(idxs[:len(sentences)//4])\n",
    "\n",
    "test_regressors = [model.infer_vector(doc.words, steps=3, alpha=0.1) for doc in sentences]\n",
    "train_targets, train_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in train_idxs])\n",
    "test_targets, test_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.65      0.76      0.70      2197\n",
      "   flatmate       0.62      0.60      0.61      2203\n",
      "   landlord       0.57      0.51      0.54      2550\n",
      "\n",
      "avg / total       0.61      0.62      0.61      6950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVC with average vectors.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = svm.LinearSVC()\n",
    "# clf = LogisticRegression()\n",
    "clf.fit(train_vectors, train_targets)\n",
    "pred = clf.predict(test_vectors)\n",
    "print(classification_report(test_targets, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to be performing that well so let's have a closer inspection of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.7880228161811829),\n",
       " ('france', 0.7539432048797607),\n",
       " ('italy', 0.7505167722702026),\n",
       " ('nz', 0.717483639717102),\n",
       " ('ireland', 0.6732045412063599),\n",
       " ('spain', 0.632851779460907),\n",
       " ('austria', 0.6309253573417664),\n",
       " ('nyc', 0.6279639601707458),\n",
       " ('sweden', 0.6032630801200867),\n",
       " ('aus', 0.6031123995780945)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
