{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "Using word embeddings to (hopefully) improve prediction accuracy of our property listing classification data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleaning import process_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_json('property_descriptions.json')\n",
    "df['description'] = df['description'].apply(process_text)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['description'], df['advertiser'], test_size=0.3)\n",
    "sentences = []\n",
    "for descriptions in x_train:\n",
    "    sentences.append(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model.\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(sentences, workers=4, size=300, \n",
    "                          min_count = 10, window = 20, sample = 1e-3)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gutted', 0.7383841872215271),\n",
       " ('leaving', 0.6741356253623962),\n",
       " ('tends', 0.6127491593360901),\n",
       " ('decided', 0.6006096601486206),\n",
       " ('sadly', 0.5577545762062073),\n",
       " ('will', 0.5556828379631042),\n",
       " ('goodbye', 0.546615481376648),\n",
       " ('missed', 0.5433094501495361),\n",
       " ('ll', 0.5380491614341736),\n",
       " ('enjoyed', 0.5273964405059814)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List closest words to \"student\"\n",
    "model.wv.most_similar(\"sad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging vectors\n",
    "An option for utilising word2Vec is by averaging the word vectors within each sample of text. Pretty basic but worth checking out how well this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.75      0.83      0.79      2625\n",
      "   flatmate       0.70      0.73      0.71      2673\n",
      "   landlord       0.66      0.58      0.61      3043\n",
      "\n",
      "avg / total       0.70      0.70      0.70      8341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def average_text(text):\n",
    "    \"\"\"Use trained word2vec model to average property descriptions\"\"\"\n",
    "    text = text.values\n",
    "    text_matrix = np.zeros((text.shape[0], 300))\n",
    "    for i in range(text.shape[0]):\n",
    "        text_sum = 0\n",
    "        count = 0\n",
    "        words = text[i]\n",
    "        for word in words:\n",
    "            try:\n",
    "                text_sum += model.wv.get_vector(word)\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if count != 0:\n",
    "            text_matrix[i,:] = text_sum / count\n",
    "        else:\n",
    "            text_matrix[i,:] = np.zeros(300)\n",
    "    return text_matrix\n",
    "            \n",
    "x_train = average_text(x_train)\n",
    "x_test = average_text(x_test)\n",
    "\n",
    "# Train SVC with average vectors.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from cleaning import process_text_doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "Listing = namedtuple('Listing', 'words tags advertiser')\n",
    "\n",
    "df = pd.read_json('property_descriptions.json')\n",
    "df['clean_description'] = df['description'].apply(process_text_doc2vec)\n",
    "sentences = []\n",
    "lookup_dict = {}\n",
    "count = 0\n",
    "for listing in df.index:\n",
    "    tag = 'LISTING_' + str(count)\n",
    "    sentences.append(Listing(df.loc[listing,'clean_description'], [tag], df.loc[listing, 'advertiser']))\n",
    "    lookup_dict[tag] = (df.loc[listing, 'advertiser'], df.loc[listing, 'description'])  # To help find values using tag\n",
    "    count += 1 \n",
    "    \n",
    "# Compare PV-DBOW and PV-DM approaches.    \n",
    "models = [\n",
    "    doc2vec.Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, workers=4),\n",
    "    doc2vec.Doc2Vec(dm=1, dm_mean=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, workers=4),\n",
    "]\n",
    "models[0].build_vocab(sentences)\n",
    "for model in models[1:]:\n",
    "    model.reset_from(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for epoch 0: 6.6322181224823\n",
      "Time elapsed for epoch 1: 6.269927978515625\n",
      "Time elapsed for epoch 2: 6.931679010391235\n",
      "Time elapsed for epoch 3: 12.18996286392212\n",
      "Time elapsed for epoch 4: 6.936272144317627\n",
      "Time elapsed for epoch 5: 11.529739141464233\n",
      "Time elapsed for epoch 6: 7.073382139205933\n",
      "Time elapsed for epoch 7: 6.6882078647613525\n",
      "Time elapsed for epoch 8: 7.061161041259766\n",
      "Time elapsed for epoch 9: 6.663622140884399\n",
      "Time elapsed for epoch 10: 7.306298017501831\n",
      "Time elapsed for epoch 11: 7.1390087604522705\n",
      "Time elapsed for epoch 12: 6.911353826522827\n",
      "Time elapsed for epoch 13: 6.7163779735565186\n",
      "Time elapsed for epoch 14: 6.496309041976929\n",
      "Time elapsed for epoch 15: 7.719903945922852\n",
      "Time elapsed for epoch 16: 6.182815074920654\n",
      "Time elapsed for epoch 17: 10.076824188232422\n",
      "Time elapsed for epoch 18: 6.182239055633545\n",
      "Time elapsed for epoch 19: 6.027113914489746\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "from numpy.random import shuffle\n",
    "\n",
    "passes = 20\n",
    "alpha = 0.025\n",
    "min_alpha = 0.001\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "from numpy.random import shuffle\n",
    "# Manually run through each epoch to shuffle data for building.\n",
    "for epoch in range(passes):\n",
    "    start = time.time()\n",
    "    shuffle(sentences)\n",
    "    for train_model in models:\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        train_model.train(sentences, total_examples=len(sentences), epochs=1)\n",
    "    alpha -= alpha_delta\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(f\"Time elapsed for epoch {epoch}: {elapsed}\")\n",
    "    \n",
    "# model.save('./listing_model.d2v')\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t4)\n",
      "\n",
      "                    Stunning one bedroom apartment located in Central London. The property is located within walking distance to Warwick Avenue tube station on one side (13 minutes walking) and Westbourne Park tube station on the other (10 minutes walking).  The property comprises of: a generous size double bedroom with a massive build in wardrobe, modern bathroom with marble tiles, a very good size open plan kitchen/living room equipped with all the mod cons (dishwasher, washing machine, fridge/freezer, coffee machine). Furthermore it benefits of wood floor throughout and high ceiling.The area is well served by public transport with 24 hours buses.The neighbourhood is ideal if you want to spend a night out, offering many restaurant and bars in Little Venice area. Bills not IncludedNo DSSPlease note that the price may vary according to the length of the tenancy.\n",
      "\n",
      "\n",
      "                    Comfortable studio apartment presented in a charming building in Hammersmith. The flat is very well maintained and it features a separate kitchen. The surrounding areas provide a multitude of things to do as well as good transport links with Barons Court tube station within walking distance. Features and facilities - separate kitchen with oven, cooker, fridge/freezer, microwave - fully furnished with double bed or sofa bed, wardrobe, chairs, coffee table. The studio will be all for yourself (Spareroom made me put current tenant information in there) \n",
      "                  \n",
      "________________________________________________________________________________\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t4)\n",
      "\n",
      "                    Stunning one bedroom apartment located in Central London. The property is located within walking distance to Warwick Avenue tube station on one side (13 minutes walking) and Westbourne Park tube station on the other (10 minutes walking).  The property comprises of: a generous size double bedroom with a massive build in wardrobe, modern bathroom with marble tiles, a very good size open plan kitchen/living room equipped with all the mod cons (dishwasher, washing machine, fridge/freezer, coffee machine). Furthermore it benefits of wood floor throughout and high ceiling.The area is well served by public transport with 24 hours buses.The neighbourhood is ideal if you want to spend a night out, offering many restaurant and bars in Little Venice area. Bills not IncludedNo DSSPlease note that the price may vary according to the length of the tenancy.\n",
      "\n",
      "\n",
      "                    --- Available Now ------ Property Newly Refurbished ------ Room Totally Furnished ----Excellent Location!Amenities, Transports walking distanceExcellent Prices!*All bills included, plus- FREE Weekly Professional Cleaning- FREE Unlimited Internet- Council Tax- Maintenance Support- Emergency Line 24hrsInterested?Contact ASAP\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "# Find most similar listing to randomly provided example. \n",
    "doc_id = np.random.randint(models[0].docvecs.count)\n",
    "listing = sentences[doc_id].tags[0]\n",
    "for model in models:\n",
    "    print('_'*80)\n",
    "    print(model)\n",
    "    similar_docs = model.docvecs.most_similar([model[listing]], topn=2)\n",
    "    for doc in similar_docs:\n",
    "            print(lookup_dict[doc[0]][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "                    Do you need to Move in Just Before Christmas?!Here's the solution!! *Flexible and 100% Safe Deposit (Mydeposit. co. uk)*All Bills + Wifi + Council Tax Included*Cleaning Service *Maintenance Service*Fully Furnished Room&KitchenCall/Text/Whatsapp me to get more info and arrange an appointment!\n",
      "\n",
      "\n",
      "                    Do you need to Move in Just Before Christmas?!Here's the solution!! ONLY £60PW EACH FOR A SHORT TERM!!*Flexible and 100% Safe Deposit (Mydeposit. co. uk)*All Bills + Wifi + Council Tax Included*Cleaning Service *Maintenance Service*Fully Furnished Room&KitchenCall/Text/Whatsapp me to get more info and arrange an appointment!\n",
      "                  \n",
      "\n",
      "                    Do you need to Move in Just Before Christmas?!Here's the solution!! ONLY £70PW EACH FOR A SHORT TERM!!*Flexible and 100% Safe Deposit (Mydeposit. co. uk)*All Bills + Wifi + Council Tax Included*Cleaning Service *Maintenance Service*Fully Furnished Room&KitchenCall/Text/Whatsapp me to get more info and arrange an appointment!\n",
      "                  \n",
      "\n",
      "                    Do you need to Move in Just Before Christmas?!Here's the solution!! Special HUGE Discount for Short term 1 Month, With ONLY 2 WEEKS DEPOSIT!*Flexible and 100% Safe Deposit (Mydeposit. co. uk)*All Bills + Wifi + Council Tax Included*Cleaning Service *Maintenance Service*Fully Furnished Room&KitchenCall/Text/Whatsapp me to get more info and arrange an appointment!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find listings written by the same estate agent clearly copying and pasting from a template. \n",
    "model = models[0]  # Only look at PV-DBOW as it performed the best.\n",
    "for doc_id in range(models[0].docvecs.count):\n",
    "    listing = sentences[doc_id].tags[0]\n",
    "    similar_docs = model.docvecs.most_similar([model[listing]], topn=5)\n",
    "    # Check if multiple listings look similar\n",
    "    if similar_docs[-1][1] > 0.8:\n",
    "        prev_doc = ''\n",
    "        print('-'*80)\n",
    "        for doc in similar_docs:\n",
    "            description = lookup_dict[doc[0]][1]\n",
    "            # Ignore exact duplicates.\n",
    "            if description != prev_doc:\n",
    "                print(lookup_dict[doc[0]][1])\n",
    "            prev_doc = description\n",
    "        break  # Just print first example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification based off the vectors\n",
    "Can we use these vectors to help classify one listings author from another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t4)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.75      0.83      0.79      2205\n",
      "   flatmate       0.71      0.69      0.70      2244\n",
      "   landlord       0.65      0.61      0.63      2501\n",
      "\n",
      "avg / total       0.70      0.71      0.70      6950\n",
      "\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t4)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.62      0.70      0.65      2205\n",
      "   flatmate       0.61      0.53      0.57      2244\n",
      "   landlord       0.52      0.53      0.53      2501\n",
      "\n",
      "avg / total       0.58      0.58      0.58      6950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train on 3/4 of the data\n",
    "idxs = np.random.permutation(range(len(sentences)))\n",
    "train_idxs = list(idxs[len(sentences)//4:])\n",
    "test_idxs = list(idxs[:len(sentences)//4])\n",
    "\n",
    "for model in models:\n",
    "    test_regressors = [model.infer_vector(doc.words, steps=3, alpha=0.1) for doc in sentences]\n",
    "    train_targets, train_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in train_idxs])\n",
    "    test_targets, test_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in test_idxs])\n",
    "    \n",
    "    clf = svm.LinearSVC()\n",
    "#     clf = LogisticRegression()\n",
    "    clf.fit(train_vectors, train_targets)\n",
    "    pred = clf.predict(test_vectors)\n",
    "    print(model)\n",
    "    print(classification_report(test_targets, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results aren't super promising. PV-DBOW seems about as good as average the word vectors, and PV-DM is worse. The BOW approah previously taken performed much better. Will try LDA to reduce the dimensionality and maybe improve the serperability of the classes being examined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.77      0.81      0.79      2205\n",
      "   flatmate       0.72      0.68      0.70      2244\n",
      "   landlord       0.62      0.62      0.62      2501\n",
      "\n",
      "avg / total       0.70      0.70      0.70      6950\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      agent       0.63      0.66      0.64      2205\n",
      "   flatmate       0.63      0.52      0.57      2244\n",
      "   landlord       0.51      0.57      0.54      2501\n",
      "\n",
      "avg / total       0.59      0.58      0.58      6950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    test_regressors = [model.infer_vector(doc.words, steps=3, alpha=0.1) for doc in sentences]\n",
    "    train_targets, train_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in train_idxs])\n",
    "    test_targets, test_vectors = zip(*[(sentences[idx].advertiser, test_regressors[idx]) for idx in test_idxs])\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    clf = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "    clf.fit(train_vectors, train_targets)\n",
    "    pred = clf.predict(test_vectors)\n",
    "    print(classification_report(test_targets, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
